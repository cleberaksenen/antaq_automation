{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "from unidecode import unidecode\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "from pyspark.sql.functions import year, month\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração dos dados \n",
    "\n",
    "Os dados foram extraídos pela ANTAQ para os anos de 2021, 2022 e 2023 e compilados utilizando o script abaixo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extração automatizada via BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://web3.antaq.gov.br/ea/sense/download.html#pt\"\n",
    "DOWNLOAD_URL = \"https://web3.antaq.gov.br/ea/sense/\"\n",
    "\n",
    "anos = [\"2021\", \"2022\", \"2023\"] #Modificar caso necessário outros períodos\n",
    "arquivos_desejados = [\"Atracação\", \"Carga\", \"Carga Conteinerizada\"]\n",
    "\n",
    "os.makedirs(\"dados_brutos\", exist_ok=True)\n",
    "\n",
    "def baixar_arquivos():\n",
    "    response = requests.get(BASE_URL)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    links = soup.find_all(\"a\", string=\"Clique aqui.\")\n",
    "\n",
    "    for link in links:\n",
    "        href = link.get(\"href\")\n",
    "        if href and href.endswith(\".zip\"):\n",
    "            nome_arquivo = link.find_previous(\"td\").text.strip()\n",
    "            ano = href.split(\"/\")[-2]\n",
    "\n",
    "            if nome_arquivo in arquivos_desejados and ano in anos:\n",
    "                arquivo_url = DOWNLOAD_URL + href\n",
    "                salvar_caminho = os.path.join(\"dados_brutos\", f\"{nome_arquivo}_{ano}.zip\")\n",
    "\n",
    "                print(f\"Baixando {arquivo_url}...\")\n",
    "                with open(salvar_caminho, \"wb\") as f:\n",
    "                    f.write(requests.get(arquivo_url).content)\n",
    "                \n",
    "                print(f\"Salvo: {salvar_caminho}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    baixar_arquivos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS. No advento de algum problema de conexão e download automático dos arquivos, é possível pular a etapa anterior e partir do script abaixo. Contanto que os dados estejam salvos na seguinte estrutura:\n",
    "\n",
    "./dados_brutos/2021/2021Atracacao.txt\n",
    "./dados_brutos/2021/2021Carga.txt\n",
    "./dados_brutos/2021/2021Carga_Conteinerizada.txt\n",
    "./dados_brutos/2022/2022Atracacao.txt\n",
    "./dados_brutos/2022/2022Carga.txt\n",
    "./dados_brutos/2022/2022Carga_Conteinerizada.txt\n",
    "./dados_brutos/2023/2023Atracacao.txt\n",
    "./dados_brutos/2023/2023Carga.txt\n",
    "./dados_brutos/2023/2023Carga_Conteinerizada.txt\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "União dos arquivos via PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"ExtracaoDados\").getOrCreate()\n",
    "\n",
    "anos = [\"2021\", \"2022\", \"2023\"] #Modificar caso necessário outros períodos\n",
    "\n",
    "arquivos = [\"Atracacao\", \"Carga\", \"Carga_Conteinerizada\"]\n",
    "\n",
    "input_dir = \"dados_brutos\"\n",
    "\n",
    "atracacao = None\n",
    "carga = None\n",
    "carga_cont = None\n",
    "\n",
    "for arquivo in arquivos:\n",
    "    input_files = [f\"{input_dir}/{ano}/{ano}{arquivo}.txt\" for ano in anos if os.path.exists(f\"{input_dir}/{ano}/{ano}{arquivo}.txt\")]\n",
    "\n",
    "    if not input_files:\n",
    "        print(\"{arquivo} não encontrado. Indo para o arquivo seguinte...\")\n",
    "        continue\n",
    "    \n",
    "    df = spark.read.option(\"header\", True).option(\"delimiter\", \";\").csv(input_files)\n",
    "\n",
    "    if arquivo == \"Atracacao\":\n",
    "        atracacao = df\n",
    "    elif arquivo == \"Carga\":\n",
    "        carga = df\n",
    "    elif arquivo == \"Carga_Conteinerizada\":\n",
    "        carga_cont = df  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela 01 (atracacao_fato)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrar apenas pelas colunas de interesse (tabela_atracacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_atracacao = [\n",
    "    'IDAtracacao', 'Tipo de Navegação da Atracação', 'CDTUP', 'Nacionalidade do Armador', \n",
    "    'IDBerco', 'FlagMCOperacaoAtracacao', 'Berço', 'Terminal', 'Porto Atracação', \n",
    "    'Município', 'Apelido Instalação Portuária', 'UF', 'Complexo Portuário', \n",
    "    'SGUF', 'Tipo da Autoridade Portuária', 'Região Geográfica', 'Nº da Capitania', \n",
    "    'Nº do IMO', 'Data Atracação', 'Data Chegada', 'Data Desatracação', 'Data Início Operação', \n",
    "    'Data Término Operação', 'Tipo de Operação'\n",
    "]\n",
    "\n",
    "atracacao_fato = atracacao.select(*colunas_atracacao)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remover valores nulos/ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "atracacao_fato = atracacao_fato.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converter colunas para o tipo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = ['Data Atracação', 'Data Chegada', 'Data Desatracação', 'Data Início Operação', 'Data Término Operação']\n",
    "\n",
    "for coluna in datas:\n",
    "    atracacao_fato = atracacao_fato.withColumn(coluna, to_timestamp(atracacao_fato[coluna], 'dd/MM/yyyy HH:mm:ss'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerar as colunas 'Ano da data de início da operação' e 'Mês da data de início da operação'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "atracacao_fato = atracacao_fato.withColumn('Ano da data de início da operação', year(atracacao_fato['Data Atracação']))\n",
    "\n",
    "atracacao_fato = atracacao_fato.withColumn('Mês da data de início da operação', month(atracacao_fato['Data Atracação']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela 02 (carga_fato)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrar apenas pelas colunas de interesse (tabelas carga e atracacao_fato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_carga = [\n",
    "    'IDCarga', 'FlagTransporteViaInterioir', 'IDAtracacao', 'Percurso Transporte em vias Interiores', \n",
    "    'Origem', 'Percurso Transporte Interiores', 'Destino', 'STNaturezaCarga', \n",
    "    'CDMercadoria', 'STSH2', 'Tipo Operação da Carga', 'STSH4', 'Carga Geral Acondicionamento', \n",
    "    'Natureza da Carga', 'ConteinerEstado', 'Sentido', 'Tipo Navegação', 'TEU', 'FlagAutorizacao', \n",
    "    'QTCarga'\n",
    "]\n",
    "\n",
    "colunas_atracacao_fato = [\n",
    "    'IDAtracacao', 'Porto Atracação', 'SGUF', 'Ano da data de início da operação', 'Mês da data de início da operação'\n",
    "]\n",
    "\n",
    "carga_intermed = carga.select(*colunas_carga)\n",
    "atracacao_fato_intermed = atracacao_fato.select(*colunas_atracacao_fato)\n",
    "\n",
    "carga_fato = carga_intermed.join(atracacao_fato_intermed, on=\"IDAtracacao\", how=\"left\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcular Peso líquido da carga:   \n",
    "carga_merged['VLPesoLiquido'] = carga_merged['VLPesoCargaBruta'] - carga_merged['VLPesoCargaConteinerizada']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "carga = carga.dropna()\n",
    "carga_cont = carga_cont.dropna()\n",
    "\n",
    "carga = carga.withColumn(\"VLPesoCargaBruta\", F.regexp_replace(\"VLPesoCargaBruta\", \",\", \".\").cast(\"float\"))\n",
    "carga_cont = carga_cont.withColumn(\"VLPesoCargaConteinerizada\", F.regexp_replace(\"VLPesoCargaConteinerizada\", \",\", \".\").cast(\"float\"))\n",
    "\n",
    "carga_merged = carga.join(carga_cont, on=\"IDCarga\", how=\"left\")\n",
    "carga_merged = carga_merged.withColumn(\"VLPesoLiquido\", F.col(\"VLPesoCargaBruta\") - F.col(\"VLPesoCargaConteinerizada\"))\n",
    "\n",
    "carga_fato = carga_fato.join(carga_merged.select(\"IDCarga\", \"VLPesoLiquido\"), on=\"IDCarga\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remoção de valores nulos/ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "carga_fato = carga_fato.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remover acentuação, cedilha, espaços e outros caracteres nos nomes das variáveis para correto carregamento no banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coluna in atracacao_fato.columns:\n",
    "    novo_nome = unidecode(coluna)\n",
    "    atracacao_fato = atracacao_fato.withColumnRenamed(coluna, novo_nome)\n",
    "\n",
    "for coluna in carga_fato.columns:\n",
    "    novo_nome = unidecode(coluna)\n",
    "    carga_fato = carga_fato.withColumnRenamed(coluna, novo_nome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "atracacao_fato = atracacao_fato.select(\n",
    "    col(\"IDAtracacao\"),\n",
    "    col(\"Tipo de Navegacao da Atracacao\").alias(\"Tipo_Navegacao_Atracacao\"),\n",
    "    col(\"CDTUP\"),\n",
    "    col(\"Nacionalidade do Armador\").alias(\"Nacionalidade_Armador\"),\n",
    "    col(\"IDBerco\"),\n",
    "    col(\"FlagMCOperacaoAtracacao\"),\n",
    "    col(\"Berco\"),\n",
    "    col(\"Terminal\"),\n",
    "    col(\"Porto Atracacao\").alias(\"Porto_Atracacao\"),\n",
    "    col(\"Municipio\"),\n",
    "    col(\"Apelido Instalacao Portuaria\").alias(\"Apelido_Instalacao_Portuaria\"),\n",
    "    col(\"UF\"),\n",
    "    col(\"Complexo Portuario\").alias(\"Complexo_Portuario\"),\n",
    "    col(\"SGUF\"),\n",
    "    col(\"Tipo da Autoridade Portuaria\").alias(\"Tipo_Autoridade_Portuaria\"),\n",
    "    col(\"Regiao Geografica\").alias(\"Regiao_Geografica\"),\n",
    "    col(\"No da Capitania\").alias(\"No_Capitania\"),\n",
    "    col(\"No do IMO\").alias(\"No_IMO\"),\n",
    "    col(\"Data Atracacao\").alias(\"Data_Atracacao\"),\n",
    "    col(\"Data Chegada\").alias(\"Data_Chegada\"),\n",
    "    col(\"Data Desatracacao\").alias(\"Data_Desatracacao\"),\n",
    "    col(\"Data Inicio Operacao\").alias(\"Data_Inicio_Operacao\"),\n",
    "    col(\"Data Termino Operacao\").alias(\"Data_Termino_Operacao\"),\n",
    "    col(\"Tipo de Operacao\").alias(\"Tipo_Operacao\"),\n",
    "    col(\"Ano da data de inicio da operacao\").alias(\"Ano_Inicio_Operacao\"),\n",
    "    col(\"Mes da data de inicio da operacao\").alias(\"Mes_Inicio_Operacao\")\n",
    ")\n",
    "\n",
    "carga_fato = carga_fato.select(\n",
    "    col(\"IDCarga\"),\n",
    "    col(\"IDAtracacao\"),\n",
    "    col(\"Origem\"),\n",
    "    col(\"Destino\"),\n",
    "    col(\"CDMercadoria\"),\n",
    "    col(\"Tipo Operacao da Carga\").alias(\"Tipo_Operacao_Carga\"),\n",
    "    col(\"Carga Geral Acondicionamento\").alias(\"Carga_Geral_Acondicionamento\"),\n",
    "    col(\"ConteinerEstado\"),\n",
    "    col(\"Tipo Navegacao\").alias(\"Tipo_Navegacao\"),\n",
    "    col(\"FlagAutorizacao\"),\n",
    "    col(\"Percurso Transporte em vias Interiores\").alias(\"Percurso_Transporte_Vias_Interiores\"),\n",
    "    col(\"Percurso Transporte Interiores\").alias(\"Percurso_Transporte_Interiores\"),\n",
    "    col(\"STNaturezaCarga\"),\n",
    "    col(\"STSH2\"),\n",
    "    col(\"STSH4\"),\n",
    "    col(\"Natureza da Carga\").alias(\"Natureza_Carga\"),\n",
    "    col(\"Sentido\"),\n",
    "    col(\"TEU\"),\n",
    "    col(\"QTCarga\"),\n",
    "    col(\"VLPesoLiquido\").alias(\"VLPesoCargaBruta\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualização das tabelas finalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------------+-------+---------------------+-----------+-----------------------+-----------+--------------------+--------------------+---------+----------------------------+--------+--------------------+----+-------------------------+-----------------+------------+-------+-------------------+-------------------+-------------------+--------------------+---------------------+--------------------+-------------------+-------------------+\n",
      "|IDAtracacao|Tipo_Navegacao_Atracacao|  CDTUP|Nacionalidade_Armador|    IDBerco|FlagMCOperacaoAtracacao|      Berco|            Terminal|     Porto_Atracacao|Municipio|Apelido_Instalacao_Portuaria|      UF|  Complexo_Portuario|SGUF|Tipo_Autoridade_Portuaria|Regiao_Geografica|No_Capitania| No_IMO|     Data_Atracacao|       Data_Chegada|  Data_Desatracacao|Data_Inicio_Operacao|Data_Termino_Operacao|       Tipo_Operacao|Ano_Inicio_Operacao|Mes_Inicio_Operacao|\n",
      "+-----------+------------------------+-------+---------------------+-----------+-----------------------+-----------+--------------------+--------------------+---------+----------------------------+--------+--------------------+----+-------------------------+-----------------+------------+-------+-------------------+-------------------+-------------------+--------------------+---------------------+--------------------+-------------------+-------------------+\n",
      "|    1194922|               Cabotagem|BRAM009|                    1|BRAM0090002|                      1|Píer de GLP|Terminal Aquaviár...|Terminal Aquaviár...|    Coari|           Terminal de Coari|Amazonas|Coari (Instalação...|  AM|      Terminal Autorizado|            Norte|  3813911888|9596870|2021-10-28 14:40:00|2021-10-28 13:45:00|2021-10-29 06:15:00| 2021-10-28 15:45:00|  2021-10-29 00:25:00|Movimentação da C...|               2021|                 10|\n",
      "|    1213788|                Interior|BRAM011|                    1|BRAM0110003|                      1|      POF 3|Terminal Aquaviár...|Terminal Aquaviár...|   Manaus|          Terminal de Manaus|Amazonas|              Manaus|  AM|      Terminal Autorizado|            Norte|  3813911888|9596870|2021-11-04 16:55:00|2021-10-29 21:30:00|2021-11-07 02:20:00| 2021-11-04 20:00:00|  2021-11-06 23:35:00|Movimentação da C...|               2021|                 11|\n",
      "|    1197543|               Cabotagem|BRAM009|                    1|BRAM0090002|                      1|Píer de GLP|Terminal Aquaviár...|Terminal Aquaviár...|    Coari|           Terminal de Coari|Amazonas|Coari (Instalação...|  AM|      Terminal Autorizado|            Norte|  3813911888|9596870|2021-11-13 15:15:00|2021-11-13 14:00:00|2021-11-14 06:10:00| 2021-11-13 16:00:00|  2021-11-14 00:40:00|Movimentação da C...|               2021|                 11|\n",
      "+-----------+------------------------+-------+---------------------+-----------+-----------------------+-----------+--------------------+--------------------+---------+----------------------------+--------+--------------------+----+-------------------------+-----------------+------------+-------+-------------------+-------------------+-------------------+--------------------+---------------------+--------------------+-------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------+-----------+-------+-------+------------+-------------------+----------------------------+---------------+--------------+---------------+-----------------------------------+------------------------------+---------------+---------+---------+--------------------+-------------+---+-------+----------------+\n",
      "| IDCarga|IDAtracacao| Origem|Destino|CDMercadoria|Tipo_Operacao_Carga|Carga_Geral_Acondicionamento|ConteinerEstado|Tipo_Navegacao|FlagAutorizacao|Percurso_Transporte_Vias_Interiores|Percurso_Transporte_Interiores|STNaturezaCarga|    STSH2|    STSH4|      Natureza_Carga|      Sentido|TEU|QTCarga|VLPesoCargaBruta|\n",
      "+--------+-----------+-------+-------+------------+-------------------+----------------------------+---------------+--------------+---------------+-----------------------------------+------------------------------+---------------+---------+---------+--------------------+-------------+---+-------+----------------+\n",
      "|28269469|    1143110|BRRO005|BRAM007|        22G0|           Interior|              Conteinerizada|          Cheio|      Interior|              S|               Interior Interest...|            Navegação Interior|      Exclusivo|Exclusivo|Exclusivo|Carga Conteinerizada|Desembarcados|  1|      1|             0.0|\n",
      "|28269482|    1143110|BRRO005|BRAM007|        42G0|           Interior|              Conteinerizada|          Cheio|      Interior|              S|               Interior Interest...|            Navegação Interior|      Exclusivo|Exclusivo|Exclusivo|Carga Conteinerizada|Desembarcados|  2|      1|    0.0030002594|\n",
      "|28269489|    1143110|BRRO005|BRAM007|        42G0|           Interior|              Conteinerizada|          Cheio|      Interior|              S|               Interior Interest...|            Navegação Interior|      Exclusivo|Exclusivo|Exclusivo|Carga Conteinerizada|Desembarcados|  2|      1|     -0.00399971|\n",
      "+--------+-----------+-------+-------+------------+-------------------+----------------------------+---------------+--------------+---------------+-----------------------------------+------------------------------+---------------+---------+---------+--------------------+-------------+---+-------+----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "atracacao_fato.show(3)\n",
    "carga_fato.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disponibilização em banco de dados (SQL Server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuração da conexão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = \"XXXXXXXXXXXX\"\n",
    "database = \"fiec_antaq\"\n",
    "username = \"XXXXXXXXXXXXXXX\"\n",
    "password = \"XXXXXXXXXXXXXXX\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = f\"mssql+pyodbc://{username}:{password}@{server}/{database}?driver=SQL+Server\"\n",
    "engine = create_engine(connection_string, fast_executemany=True)\n",
    "\n",
    "# Conversão para Pandas:\n",
    "atracacao_fato_pd = atracacao_fato.toPandas()\n",
    "carga_fato_pd = carga_fato.toPandas()\n",
    "\n",
    "def importar_dados_para_sql(df, tabela):\n",
    "    try:\n",
    "        df.to_sql(tabela, engine, if_exists=\"append\", index=False, chunksize=1000)\n",
    "    except Exception as e:\n",
    "        print(\"Erro ao importar os dados para a tabela {tabela}: {e}\")\n",
    "\n",
    "importar_dados_para_sql(atracacao_fato_pd, \"atracacao_fato\")\n",
    "importar_dados_para_sql(carga_fato_pd, \"carga_fato\")\n",
    "\n",
    "engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
